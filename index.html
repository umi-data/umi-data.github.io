<!DOCTYPE html>
<html lang="en" class="has-navbar-fixed-top">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>UMI Robot Dataset Community</title>


    <!-- Bulma CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css">

    <!-- Highlight.js CSS -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>

    <!-- Custom CSS -->
    <link rel="stylesheet" href="./index.css">

    <!-- and it's easy to individually load additional languages -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/python.min.js"></script>

    <script>hljs.highlightAll();</script>

    <script>
        let rows = [{
            "Project": "UMI",
            "Project Link": "https://umi-gripper.github.io/",
            "task": "Cup Rearrangement",
            "data_links": {
                "MP4": "#", "Zarr": "#",
            },
            "obs": ["Image", "Proprio"],
            "actions": ["6 DoF Movement", "Gripper Width"],
            "n_demos": 1400,
            "n_envs": 30,
            "contact": "chuerpan@stanford.edu",
            "license": "MIT",
            "citation": `@inproceedings{chi2024universal,
    title={Universal Manipulation Interface: In-The-Wild Robot Teaching Without In-The-Wild Robots},
    author={Chi, Cheng and Xu, Zhenjia and Pan, Chuer and Cousineau, Eric and Burchfiel, Benjamin and Feng, Siyuan and Tedrake, Russ and Song, Shuran},
    booktitle={Proceedings of Robotics: Science and Systems (RSS)},
    year={2024}`
        },
        {
            "Project": "ManiWAV",
            "Project Link": "https://mani-wav.github.io/",
            "task": "Whiteboard Shape Wipe",
            "data_links": {
                "Zarr": "https://real.stanford.edu/maniwav/data/wipe/replay_buffer.zarr.zip"
            },
            "obs": ["Image", "Proprio", "Audio"],
            "actions": ["6 DoF Movement", "Gripper Width"],
            "n_demos": 119,
            "n_envs": 1,
            "contact": "liuzeyi@stanford.edu",
            "license": "MIT",
            "citation": `@article{liu2024maniwav,
    title={ManiWAV: Learning Robot Manipulation from In-the-Wild Audio-Visual Data},
    author={Liu, Zeyi and Chi, Cheng and Cousineau, Eric and Kuppuswamy, Naveen and Burchfiel, Benjamin and Song, Shuran},
    journal={arXiv preprint arXiv:2406.19464},
    year={2024}
}`
        },
        {
            "task": "Flip bagel",
            "data_links": {
                "Zarr": "https://real.stanford.edu/maniwav/data/flip/replay_buffer.zarr.zip"
            },
            "obs": ["Image", "Proprio", "Audio"],
            "actions": ["6 DoF Movement", "Gripper Width"],
            "n_demos": 283,
            "n_envs": 1,
            "license": "MIT",
        },
        {
            "task": "Pour dice",
            "data_links": {
                "Zarr": "https://real.stanford.edu/maniwav/data/pour/replay_buffer.zarr.zip"
            },
            "obs": ["Image", "Proprio", "Audio"],
            "actions": ["6 DoF Movement", "Gripper Width"],
            "n_demos": 145,
            "n_envs": 1,
            "license": "MIT",
        },
        {
            "task": "Strap wires with velcro tape",
            "data_links": {
                "Zarr": "https://real.stanford.edu/maniwav/data/velcro_tape/replay_buffer.zarr.zip"
            },
            "obs": ["Image", "Proprio", "Audio"],
            "actions": ["6 DoF Movement", "Gripper Width"],
            "n_demos": 193,
            "n_envs": 1,
            "license": "MIT",
        },
        {
            "task": "Flip bagel in the wild",
            "data_links": {
                "MP4": "https://real.stanford.edu/maniwav/data/bagel_in_wild/demos/",
                "Zarr": "https://real.stanford.edu/maniwav/data/bagel_in_wild/replay_buffer.zarr.zip"
            },
            "obs": ["Image", "Proprio", "Audio"],
            "actions": ["6 DoF Movement", "Gripper Width"],
            "n_demos": 274,
            "n_envs": 7,
            "license": "MIT",
        },
        {
            "Project": "UMI on Legs",
            "Project Link": "https://umi-on-legs.github.io/",
            "task": "Kettlebell Pushing",
            "data_links": {
                "MP4": "https://real.stanford.edu/umi-on-legs/pushing_2024_05_29_huy/",
                "Zarr": "https://real.stanford.edu/umi-on-legs/pushing_2024_05_29_huy.zarr.zip"
            },
            "obs": ["Image", "Proprio"],
            "actions": ["6 DoF Movement", "Gripper Width"],
            "n_demos": 14,
            "n_envs": 1,
            "contact": "huyha@stanford.edu",
            "license": "MIT",
            "citation": `@inproceedings{ha2024umilegs,
  title={{UMI} on Legs: Making Manipulation Policies Mobile with Manipulation-Centric Whole-body Controllers},
  author={Huy Ha and Yihuai Gao and Zipeng Fu and Jie Tan and Shuran Song},
  year={2024},
  booktitle={Proceedings of the 2024 Conference on Robot Learning},
}`
        },
        {
            "task": "Tennis Ball Basket Toss",
            "data_links": {
                "MP4": "https://real.stanford.edu/umi-on-legs/tossing/",
                "Zarr": "https://real.stanford.edu/umi-on-legs/tossing.zarr.zip"
            },
            "obs": ["Image", "Proprio"],
            "actions": ["6 DoF Movement", "Gripper Width"],
            "n_demos": 500,
            "n_envs": 1,
            "license": "MIT",
        },
        ];

        function generateTable(data) {
            let tableBody = document.querySelector("table tbody");
            tableBody.innerHTML = ""; // Clear existing content

            data.forEach((row) => {
                let tr = document.createElement("tr");

                // Project Name
                if (row["Project"]) {
                    let projectName = document.createElement("td");
                    let projectLink = document.createElement("a");
                    projectLink.href = row["Project Link"] || "#";
                    projectLink.textContent = row["Project"];
                    projectName.appendChild(projectLink);
                    tr.appendChild(projectName);
                } else {
                    tr.appendChild(document.createElement("td"));
                }

                // Contact
                let contact = document.createElement("td");
                if (row["contact"]) {
                    let contactLink = document.createElement("a");
                    contactLink.href = `mailto:${row["contact"]}`;
                    contactLink.textContent = row["contact"];
                    contact.appendChild(contactLink);
                }
                tr.appendChild(contact);

                // Task Name
                let taskName = document.createElement("td");
                taskName.textContent = row["task"];
                tr.appendChild(taskName);

                // Data Links
                let dataLinks = document.createElement("td");
                for (let format in row["data_links"]) {
                    let link = document.createElement("a");
                    link.href = row["data_links"][format];
                    link.textContent = format;
                    link.style.marginRight = "10px";
                    dataLinks.appendChild(link);
                }
                tr.appendChild(dataLinks);

                // Observations
                let obs = document.createElement("td");
                let obsTags = row["obs"].map(obsItem => {
                    let span = document.createElement("span");
                    span.classList.add("tag", "is-normal");
                    if (obsItem.toLowerCase() === "image") {
                        span.classList.add("is-primary");
                    } else if (obsItem.toLowerCase() === "proprio") {
                        span.classList.add("is-info");
                    } else if (obsItem.toLowerCase() === "bimanual") {
                        span.classList.add("is-success");
                    } else if (obsItem.toLowerCase() === "audio") {
                        span.classList.add("is-danger");
                    }
                    span.textContent = obsItem;
                    return span;
                });
                obsTags.forEach(tag => obs.appendChild(tag));
                tr.appendChild(obs);

                // Actions
                let actions = document.createElement("td");
                let actionTags = row["actions"].map(actionItem => {
                    let span = document.createElement("span");
                    span.classList.add("tag", "is-normal");
                    if (actionItem.toLowerCase() === "6 dof movement") {
                        span.classList.add("is-primary", "is-light");
                    } else if (actionItem.toLowerCase() === "gripper width") {
                        span.classList.add("is-link", "is-light");
                    } else if (actionItem.toLowerCase() === "bimanual") {
                        span.classList.add("is-success", "is-light");
                    }
                    span.textContent = actionItem;
                    return span;
                });
                actionTags.forEach(tag => actions.appendChild(tag));
                tr.appendChild(actions);

                // Number of Demonstrations
                let demos = document.createElement("td");
                demos.textContent = row["n_demos"];
                tr.appendChild(demos);

                // Number of Environments
                let envs = document.createElement("td");
                envs.textContent = row["n_envs"];
                tr.appendChild(envs);

                // License
                let license = document.createElement("td");
                license.textContent = row["license"];
                tr.appendChild(license);

                // Citation
                let citation = document.createElement("td");
                if (row["citation"]) {
                    let citationPre = document.createElement("pre");
                    citationPre.style.maxWidth = "400px";
                    citationPre.style.overflowX = "auto";
                    let citationCode = document.createElement("code");
                    citationCode.textContent = row["citation"];
                    citationPre.appendChild(citationCode);
                    citation.appendChild(citationPre);
                }
                tr.appendChild(citation);

                tableBody.appendChild(tr);
            });
        }


        // Call the function after DOM has loaded
        document.addEventListener('DOMContentLoaded', function () {
            generateTable(rows);
        });

    </script>
</head>

<body>
    <!-- Navbar -->
    <nav class="navbar is-transparent is-fixed-top" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
            <!-- Logo Placeholder -->
            <a class="navbar-item" href="https://umi-data.github.io/">
                <img src="./logo.png" alt="Logo" style="max-height: 3rem;"> <!-- Replace with your logo -->
                <span class="is-size-4 has-text-weight-bold">UMI</span>
            </a>
        </div>

        <div id="navbarBasicExample" class="navbar-menu">
            <div class="navbar-start is-hidden-touch"> <!-- Hidden on mobile -->
                <a class="navbar-item" href="#principles">
                    Principles
                </a>

                <a class="navbar-item" href="#datasets">
                    Datasets
                </a>

                <a class="navbar-item" href="#data-format">
                    Data Format
                </a>
            </div>

            <div class="navbar-end">
                <div class="navbar-item">
                    <div class="buttons">
                        <a class="button is-light" href="#list-your-data">
                            List Your Data
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </nav>


    <!-- Hero Section -->
    <section class="hero is-link is-fullheight video" style="overflow: hidden; position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
        <div class="hero-video" style="height: 100%; width: 177.77777778vh; min-width: 100%;min-height: 56.25vw;">
            <video playsinline autoplay muted loop>
                <source src=" ./teaser.mp4" type="video/mp4">
            </video>
        </div>
        <div class="hero-video is-hidden-tablet is-inline-block-mobile"
            style="height: 154.28571428vw; width: 100%; min-width:64.81481481vh;min-height:100%;">
            <video playsinline autoplay muted loop>
                <source src=" ./teaser-mobile.mp4" type="video/mp4">
            </video>
        </div>
        <div class="overlay"></div>



        <div class="hero-body">
            <div class="container has-text-centered">
                <h1 class="title is-1 publication-title is-size-1-mobile" style="font-size: 8rem;">
                    Data is better when universally sharable
                </h1>
                <!-- <h2 class="subtitle"></h2> -->
            </div>
        </div>
    </section>

    <div style="height: 100vh;"></div>

    <section class="section is-small" id="overview">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column is-four-fifths has-text-justified is-hidden-mobile">
                    <h2 class="subtitle ">
                        UMI is a physical and policy interface that allows robot data to be shared between many robots.
                        With just a GoPro and a 3D printed gripper, any new robot platform can get up and running with
                        UMI policies without any robot-specific data collection!
                    </h2>
                    <br>
                    <h2 class="subtitle">
                        <strong>The best part?</strong>
                        With just a GoPro and a 3D printed gripper, any new robot platform can get up and running with
                        UMI policies without any robot-specific data collection!
                    </h2>
                </div>

                <div class="column is-four-fifths is-hidden-tablet has-text-justified-mobile">
                    <p>
                        UMI is a physical and policy interface that allows robot data to be shared between many robots.
                    </p>
                    <br>
                    <p>
                        <strong>The best part?</strong>
                        With just a GoPro and a 3D printed gripper, any new robot platform can get up and running with
                        UMI policies without any robot-specific data collection!
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- UMI Community Dataset Principles Section -->
    <section class="section has-text-centered" id="principles">
        <div class="container content box has-text-justified">
            <div class="columns is-centered">
                <div class="column is-four-fifths p-6">
                    <h2>UMI Community Principles</h2>
                    <h3>üìà No dataset is too small; small data adds up.</h3>
                    <p>
                        Even a simple, single-task dataset with 50 demonstrations is valuable. As long as you're happy
                        to
                        share it, we are happy to list it here.
                        Every bit of data contributes to the community‚Äôs collective knowledge.
                    </p>

                    <h3>‚ôªÔ∏è UMI is a constantly evolving design.</h3>
                    <p>
                        There‚Äôs no strict definition of UMI data. You are encouraged to contribute datasets even if they
                        don‚Äôt follow the same hardware or data format.
                        We welcome enhancements to the UMI design‚Äîbe it new sensors (e.g., <a
                            href="https://mani-wav.github.io/">ManiWav</a>),
                        finger designs, or cameras (e.g., <a href="link-to-fastumi">fastUMI</a>).
                        Even if your data is not directly transferable to the current UMI setup, it can still be useful
                        for
                        pretraining or other creative applications.
                        If it can benefit the UMI community, it‚Äôs worth listing!
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Dataset Table Section -->
    <section class="section" id="datasets">
        <div class="container">
            <h2 class="title has-text-centered">UMI Datasets</h2>

            <div class="table-container">
                <table class="table is-striped is-hoverable is-fullwidth">
                    <thead>
                        <tr>
                            <th>Project Name</th>
                            <th>Contact</th>
                            <th style="min-width: 200px;">Task</th>
                            <th style="min-width: 100px;">Data Links</th>
                            <th>Obs</th>
                            <th>Actions</th>
                            <th style="min-width: 100px;"># Demos</th>
                            <th style="min-width: 100px;"># Envs</th>
                            <th>License</th>
                            <th style="max-width: 400px;">Citation</th> <!-- Set max width for citation -->
                        </tr>
                    </thead>
                    <tbody>
                    </tbody>
                </table>
            </div>
        </div>
    </section>



    <!-- Listing Your Data Section -->
    <section class="section" id="list-your-data">
        <div class="container">
            <h2 class="title is-3">üìã Listing Your Data</h2>

            <div class="content">
                <p>If you would like your data to be listed here, please provide the following information:</p>
                <ul>
                    <li><strong>Project:</strong> The name of the project and link to the project website for additional
                        context.</li>
                    <li><strong>License:</strong> The licensing terms under which the data is distributed (e.g.,
                        MIT, GPL, CC BY 4.0).</li>
                    <li><strong>Citation:</strong> Information on how to properly cite the dataset if used.</li>
                    <li><strong>Contact person:</strong> The name and email of the individual responsible for the
                        dataset.</li>
                    <li><strong>Tasks</strong>:
                        <ul>
                            <li><strong>Metadata:</strong> This includes the task name, the observations (e.g., Image,
                                Proprio, Audio, Bimanual), and the actions (e.g., 6 DoF Movement, Gripper Width,
                                Bimanual).</li>
                            <li><strong>Link to Data:</strong> A direct link to where each of the data formats
                                can be accessed. For instance, the link for MP4 might be a google drive link, while the
                                link for
                                a Zarr file might be hosted on the project's webserver. If you're unsure of which data
                                format to use,
                                consider
                                using/extending the <a href="#data-format">UMI data format</a>.</li>
                            <li><strong>Number of demonstrations:</strong> The number of demonstrations in the dataset.
                            </li>
                            <li><strong>Number of environments:</strong> The number of environments in which the data
                                was
                                collected.</li>
                        </ul>
                    </li>
                </ul>

                <p>Please send this information to <a href="mailto:huyha@stanford.edu">huyha@stanford.edu</a> for review
                    and
                    inclusion in our listing.</p>
            </div>

            <!-- Disclaimer Callout -->
            <article class="message is-warning">
                <div class="message-body">
                    <strong>Disclaimer:</strong> We only provide a list of references to existing data for researchers
                    to easily search and find datasets. We do not own or host the datasets listed here. For questions
                    about specific datasets, please reach out to the project owners directly.
                </div>
            </article>
        </div>
    </section>



    <!-- Data Format Panel -->
    <section class="section" id="data-format">
        <div class="container content">

            <h2 id="-dataset-format">üìö Dataset Format</h2>
            <p>UMI has multiple tiers of data storage formats:</p>
            <ul>
                <li><strong>GoPro</strong>: Just a folder of GoPro MP4s :)</li>
                <li><strong>SLAM</strong> Output of ORB_SLAM3 pipeline (volatile)</li>
                <li><strong>Zarr</strong> A single zip file optimized for fast random reading for training.</li>
            </ul>
            <h3 id="zarr-data-format">Zarr data format</h3>
            <p>Following <a href="https://diffusion-policy.cs.columbia.edu/">Diffusion Policy</a>, UMI uses <a
                    href="https://zarr.dev/">Zarr</a> as the container for training datasets. Zarr is similar to <a
                    href="https://docs.hdfgroup.org/hdf5/v1_14/_intro_h_d_f5.html">HDF5</a> but offers better
                flexibility for storage backends, chunking, compressors, and parallel access. </p>
            <p>Conceptually, Zarr can be understood as a nested <code>dict</code> of &quot;numpy arrays&quot;. For
                example, here is the structure of the <code>example_demo_session</code> dataset.</p>
            <pre><code class="lang-python">import Zarr
from diffusion_policy.codecs.imagecodecs_numcodecs import register_codecs, JpegXl
register_codecs()

root = zarr.open('example_demo_session/dataset.zarr.zip')
print(root.tree())
&gt;&gt;&gt;
/
 ‚îú‚îÄ‚îÄ data
 ‚îÇ   ‚îú‚îÄ‚îÄ camera0_rgb (<span class="hljs-number">2315</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>, <span class="hljs-number">3</span>) uint8
 ‚îÇ   ‚îú‚îÄ‚îÄ robot0_demo_end_pose (<span class="hljs-number">2315</span>, <span class="hljs-number">6</span>) float64
 ‚îÇ   ‚îú‚îÄ‚îÄ robot0_demo_start_pose (<span class="hljs-number">2315</span>, <span class="hljs-number">6</span>) float64
 ‚îÇ   ‚îú‚îÄ‚îÄ robot0_eef_pos (<span class="hljs-number">2315</span>, <span class="hljs-number">3</span>) float32
 ‚îÇ   ‚îú‚îÄ‚îÄ robot0_eef_rot_axis_angle (<span class="hljs-number">2315</span>, <span class="hljs-number">3</span>) float32
 ‚îÇ   ‚îî‚îÄ‚îÄ robot0_gripper_width (<span class="hljs-number">2315</span>, <span class="hljs-number">1</span>) float32
 ‚îî‚îÄ‚îÄ meta
     ‚îî‚îÄ‚îÄ episode_ends (<span class="hljs-number">5</span>,) int64
</code></pre>
            <h4 id="replaybuffer">ReplayBuffer</h4>
            <p>We implemented the <code>ReplayBuffer</code> class to access Zarr data conveniently.</p>
            <pre><code class="lang-python">from diffusion_policy.common.replay_buffer import <span class="hljs-symbol">ReplayBuffer</span>

replay_buffer = <span class="hljs-symbol">ReplayBuffer</span>.create_from_group(root)
replay_buffer.n_episodes
&gt;&gt;&gt; <span class="hljs-number">5</span>

# reading an episode
ep = replay_buffer.get_episode(<span class="hljs-number">0</span>)
ep.keys()
&gt;&gt;&gt; dict_keys([<span class="hljs-string">'camera0_rgb'</span>, <span class="hljs-string">'robot0_demo_end_pose'</span>, <span class="hljs-string">'robot0_demo_start_pose'</span>, <span class="hljs-string">'robot0_eef_pos'</span>, <span class="hljs-string">'robot0_eef_rot_axis_angle'</span>, <span class="hljs-string">'robot0_gripper_width'</span>])

ep[<span class="hljs-string">'robot0_gripper_width'</span>]
&gt;&gt;&gt;
array([[<span class="hljs-number">0.07733118</span>],
       [<span class="hljs-number">0.07733118</span>],
       [<span class="hljs-number">0.07734068</span>],
...
       [<span class="hljs-number">0.08239228</span>],
       [<span class="hljs-number">0.08236252</span>],
       [<span class="hljs-number">0.0823558</span> ]], dtype=float32)
</code></pre>
            <h4 id="data-group">Data Group</h4>
            <p>In <code>root[&#39;data&#39;]</code> &quot;dict,&quot; we have a group of arrays containing demonstration
                episodes concatenated along the first dimension (time/step). In this dataset, we have 2315 steps across
                five episodes. In UMI, data has a frame rate of 60Hz (59.94Hz), matching the recording frame rate of
                GoPros. All arrays in <code>root[&#39;data&#39;]</code> must have the same size in their first (time)
                dimension.</p>
            <pre><code class="lang-python">root[<span class="hljs-string">'data'</span>][<span class="hljs-symbol">'robot0_eef_pos'</span>]
&gt;&gt;&gt; <span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">zarr.core.Array</span> '/<span class="hljs-attr">data</span>/<span class="hljs-attr">robot0_eef_pos</span>' (<span class="hljs-attr">2315</span>, <span class="hljs-attr">3</span>) <span class="hljs-attr">float32</span>&gt;</span></span>

root[<span class="hljs-string">'data'</span>][<span class="hljs-symbol">'robot0_eef_pos'</span>][<span class="hljs-string">0</span>]
&gt;&gt;&gt; array([ 0.1872826 , -0.35130176,  0.1859438 ], dtype=float32)

root[<span class="hljs-string">'data'</span>][<span class="hljs-symbol">'robot0_eef_pos'</span>][<span class="hljs-string">:</span>]
&gt;&gt;&gt;
array([[ 0.1872826 , -0.35130176,  0.1859438 ],
<span class="hljs-code">       [ 0.18733297, -0.3509169 ,  0.18603411],</span>
<span class="hljs-code">       [ 0.18735182, -0.3503186 ,  0.18618457],</span>
<span class="hljs-code">       ...,</span>
<span class="hljs-code">       [ 0.12694108, -0.3326249 ,  0.13230264],</span>
<span class="hljs-code">       [ 0.12649481, -0.3347473 ,  0.1347403 ],</span>
<span class="hljs-code">       [ 0.12601827, -0.33651358,  0.13699797]], dtype=float32)</span>
</code></pre>
            <h4 id="metadata-group">Metadata Group</h4>
            <p>How do we know the start and end of each episode? We store an integer array
                <code>root[&#39;meta&#39;][&#39;episode_ends&#39;]</code> that contains each episode&#39;s
                <code>end</code> index into <code>data</code> arrays.
                For example, the first episode can be accessed with
                <code>root[&#39;data&#39;][&#39;robot0_eef_pos&#39;][0:468]</code> and the second episode can be
                accessed with <code>root[&#39;data&#39;][&#39;robot0_eef_pos&#39;][468:932]</code>.
            </p>
            <pre><code class="lang-python">root[<span class="hljs-string">'meta'</span>][<span class="hljs-symbol">'episode_ends'</span>][<span class="hljs-string">:</span>]
&gt;&gt;&gt; array([ 468,  932, 1302, 1710, 2315])
</code></pre>
            <h4 id="data-array-chunking-and-compression">Data Array Chunking and Compression</h4>
            <p>Note that all arrays in the dataset are of type <code>zarr.core.Array</code> instead of
                <code>numpy.ndarray</code>. While offering similar API to numpy arrays, Zarr arrays are optimized for
                fast on-disk storage with <em>chunked compression</em>. For example, camera images
                <code>root[&#39;data&#39;][&#39;camera0_rgb&#39;]</code> is stored with chunk size
                <code>(1, 224, 224, 3)</code> and <code>JpegXl</code> compression. When reading from a Zarr array, a
                chunk of data is loaded from disk storage and decompressed to a numpy array.
            </p>

            <!-- Disclaimer Callout -->
            <article class="message is-warning">
                <div class="message-body">
                    <strong>üí°</strong> For optimal performance, the chunk size has to be chosen carefully. A
                    chunk size too big means that the
                    data loader will decompress the data more than necessary (e.g., chunks=(100, 224, 244, 3) will
                    decompress and discard 99 images when accessing [0]). In contrast, having the chunk size too small
                    will
                    incur additional overhead and reduce compression rate (e.g., chunks=(1,14,14,3) means each image is
                    split into 256 chunks).
                </div>
            </article>
            <pre><code class="lang-python">root[<span class="hljs-string">'data'</span>][<span class="hljs-symbol">'camera0_rgb'</span>]
&gt;&gt;&gt; <span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">zarr.core.Array</span> '/<span class="hljs-attr">data</span>/<span class="hljs-attr">camera0_rgb</span>' (<span class="hljs-attr">2315</span>, <span class="hljs-attr">224</span>, <span class="hljs-attr">224</span>, <span class="hljs-attr">3</span>) <span class="hljs-attr">uint8</span>&gt;</span></span>

root[<span class="hljs-string">'data'</span>][<span class="hljs-symbol">'camera0_rgb'</span>].chunks # chunk size
&gt;&gt;&gt; (1, 224, 224, 3)

root[<span class="hljs-string">'data'</span>][<span class="hljs-symbol">'camera0_rgb'</span>].nchunks # number of chunks
&gt;&gt;&gt; 2315

root[<span class="hljs-string">'data'</span>][<span class="hljs-symbol">'camera0_rgb'</span>].compressor
&gt;&gt;&gt; JpegXl(decodingspeed=None, distance=None, effort=None, index=None, keeporientation=None, level=99, lossless=False, numthreads=1, photometric=None, planar=None, usecontainer=None)

root[<span class="hljs-string">'data'</span>][<span class="hljs-symbol">'camera0_rgb'</span>][<span class="hljs-string">0</span>]
&gt;&gt;&gt;
array([[[ 7,  6, 15],
<span class="hljs-code">        [ 7,  6, 15],</span>
<span class="hljs-code">        [ 4,  4, 13],</span>
<span class="hljs-code">        ...,</span>
<span class="hljs-code">        [ 6,  7, 15],</span>
<span class="hljs-code">        [ 4,  7, 14],</span>
<span class="hljs-code">        [ 3,  6, 13]],</span>

<span class="hljs-code">       ...,</span>

<span class="hljs-code">       [[ 0,  0,  0],</span>
<span class="hljs-code">        [ 0,  0,  0],</span>
<span class="hljs-code">        [ 0,  0,  0],</span>
<span class="hljs-code">        ...,</span>
<span class="hljs-code">        [ 0,  0,  0],</span>
<span class="hljs-code">        [ 0,  0,  0],</span>
<span class="hljs-code">        [ 0,  0,  0]]], dtype=uint8)</span>
</code></pre>
            <p>We use a relatively large chunk size for low-dimensional data. Since these data are cached into a numpy
                array inside <code>UmiDataset,</code> no read IOPS overhead is introduced.</p>
            <pre><code class="lang-python">root[<span class="hljs-string">'data'</span>][<span class="hljs-symbol">'robot0_eef_pos'</span>].chunks
&gt;&gt;&gt; (468, 3)

root[<span class="hljs-string">'data'</span>][<span class="hljs-symbol">'robot0_eef_pos'</span>].compressor # uncompressed chunks
&gt;&gt;&gt; None
</code></pre>
            <h4 id="in-memory-compression">In-memory Compression</h4>
            <p>During training, streaming datasets from a network drive is often bottlenecked by <a
                    href="https://en.wikipedia.org/wiki/IOPS">IOPS</a>, especially when multiple GPUs/nodes are reading
                from the same network drive. While loading the entire dataset to memory works around the IOPS
                bottleneck, an uncompressed UMI dataset often does not fit in RAM.</p>
            <p>We found streaming <em>compressed</em> datasets from RAM a good tradeoff between memory footprint and
                read performance.</p>
            <pre><code class="lang-python">root.store
&gt;&gt;&gt; &lt;zarr.storage.ZipStore at <span class="hljs-number">0x76b73017d400</span>&gt;

ram_store = zarr.MemoryStore()
# load stored chunks in bytes directly to memory, without decompression
zarr.convenience.copy_store(root.store, ram_store)
ram_root = zarr.group(ram_store)
print(ram_root.tree())
&gt;&gt;&gt;
/
 ‚îú‚îÄ‚îÄ data
 ‚îÇ   ‚îú‚îÄ‚îÄ camera0_rgb (<span class="hljs-number">2315</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>, <span class="hljs-number">3</span>) uint8
 ‚îÇ   ‚îú‚îÄ‚îÄ robot0_demo_end_pose (<span class="hljs-number">2315</span>, <span class="hljs-number">6</span>) float64
 ‚îÇ   ‚îú‚îÄ‚îÄ robot0_demo_start_pose (<span class="hljs-number">2315</span>, <span class="hljs-number">6</span>) float64
 ‚îÇ   ‚îú‚îÄ‚îÄ robot0_eef_pos (<span class="hljs-number">2315</span>, <span class="hljs-number">3</span>) float32
 ‚îÇ   ‚îú‚îÄ‚îÄ robot0_eef_rot_axis_angle (<span class="hljs-number">2315</span>, <span class="hljs-number">3</span>) float32
 ‚îÇ   ‚îî‚îÄ‚îÄ robot0_gripper_width (<span class="hljs-number">2315</span>, <span class="hljs-number">1</span>) float32
 ‚îî‚îÄ‚îÄ meta
     ‚îî‚îÄ‚îÄ episode_ends (<span class="hljs-number">5</span>,) int64


# loading compressed data to RAM with ReplayBuffer
ram_replay_buffer = ReplayBuffer.copy_from_store(
    root.store,
    zarr.MemoryStore()
)
ep = ram_replay_buffer.get_episode(<span class="hljs-number">0</span>)
</code></pre>

        </div>
    </section>



    <!-- Contact Section -->
    <section class="section has-background-light" id="contact">
        <div class="container">
            <div class="content has-text-centered">
                <h3 class="title is-4">Contact</h3>
                <p>
                    For questions or to have your UMI dataset listed on this website, please reach out to
                    <a href="https://www.cs.columbia.edu/~huy/" target="_blank">Huy Ha</a>.
                </p>
            </div>
        </div>
    </section>

</body>

<footer>
    <script>// JavaScript to handle tab switching
        document.addEventListener('DOMContentLoaded', () => {
            const tabs = document.querySelectorAll('.panel-tabs a');
            const contents = document.querySelectorAll('.panel-content');

            tabs.forEach(tab => {
                tab.addEventListener('click', () => {
                    // Remove active class from all tabs
                    tabs.forEach(item => item.classList.remove('is-active'));
                    // Hide all content sections
                    contents.forEach(content => content.classList.add('is-hidden'));

                    // Add active class to clicked tab
                    tab.classList.add('is-active');

                    // Show the corresponding content
                    const tabContent = document.getElementById(`${tab.dataset.tab}-content`);
                    tabContent.classList.remove('is-hidden');
                });
            });
        });
    </script>
</footer>

</html>